{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df974c7e",
   "metadata": {},
   "source": [
    "# Bring Your Own Model with SageMaker Script Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a45ec",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bbca4",
   "metadata": {},
   "source": [
    "이 노트북은 Scikit-Learn, PyTorch 및 XgBoost와 같은 다양한 프레임워크를 위한 SageMaker의 사전 빌드된 컨테이너와 함께 SageMaker 외부에서 사용하는 것과 유사한 사용자 지정 교육 및 추론 스크립트를 사용하여 자신의 모델을 가져올 수 있는 방법을 보여줍니다.\n",
    "\n",
    "SageMaker 스크립트 모드는 유연하므로 사용자 정의 Python 라이브러리와 같은 자체 종속성을 교육 및 추론에 포함시키는 방법에 대한 예도 볼 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655a7fd",
   "metadata": {},
   "source": [
    "<img title=\"SageMaker Script Mode\" alt=\"Solution diagram\" src=\"solution-diagram.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283026ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.serializers import NumpySerializer, JSONSerializer, CSVSerializer\n",
    "from sagemaker.deserializers import NumpyDeserializer, JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "from generate_synthetic_housing_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ff834",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8625a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Useful SageMaker variables\n",
    "try:\n",
    "    # You're using a SageMaker notebook\n",
    "    sess = sagemaker.Session()\n",
    "    bucket = sess.default_bucket()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    # You're using a notebook somewhere else\n",
    "    print(\"Setting role and SageMaker session manually...\")\n",
    "    bucket = \"yudong-data\"\n",
    "    region = boto3.Session().region_name\n",
    "\n",
    "    iam = boto3.client(\"iam\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    sagemaker_execution_role_name = (\n",
    "        # TODO: Change this to your role name\n",
    "        \"AmazonSageMaker-ExecutionRole-20201218T151409\" \n",
    "    )\n",
    "    role = iam.get_role(RoleName=sagemaker_execution_role_name)[\"Role\"][\"Arn\"]\n",
    "    boto3.setup_default_session(region_name=region, profile_name=\"default\")\n",
    "    sess = sagemaker.Session(sagemaker_client=sagemaker_client, default_bucket=bucket)\n",
    "\n",
    "# Local data paths\n",
    "train_dir = os.path.join(os.getcwd(), \"data/train\")\n",
    "test_dir = os.path.join(os.getcwd(), \"data/test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Data paths in S3\n",
    "s3_prefix = \"script-mode-workflow\"\n",
    "csv_s3_prefix = f\"{s3_prefix}/csv\"\n",
    "csv_s3_uri = f\"s3://{bucket}/{s3_prefix}/csv\"\n",
    "numpy_train_s3_prefix = f\"{s3_prefix}/numpy/train\"\n",
    "numpy_train_s3_uri = f\"s3://{bucket}/{numpy_train_s3_prefix}\"\n",
    "numpy_test_s3_prefix = f\"{s3_prefix}/numpy/test\"\n",
    "numpy_test_s3_uri = f\"s3://{bucket}/{numpy_test_s3_prefix}\"\n",
    "csv_train_s3_uri = f\"{csv_s3_uri}/train\"\n",
    "csv_test_s3_uri = f\"{csv_s3_uri}/test\"\n",
    "\n",
    "# Enable Local Mode training\n",
    "enable_local_mode_training = False\n",
    "\n",
    "# Endpoint names\n",
    "sklearn_endpoint_name = \"randomforestregressor-endpoint\"\n",
    "pytorch_endpoint_name = \"pytorch-endpoint\"\n",
    "xgboost_endpoint_name = \"xgboost-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7edd3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::806174985048:role/service-role/AmazonSageMaker-ExecutionRole-20201218T151409'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d545ce8",
   "metadata": {},
   "source": [
    "### Prepare Synthetic Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6178b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_houses(1506)\n",
    "\n",
    "# Get training columns\n",
    "train_cols = list(df.columns)\n",
    "del train_cols[-1]\n",
    "train_cols\n",
    "\n",
    "# Split data\n",
    "training_index = math.floor(0.8 * df.shape[0])\n",
    "x_train, y_train = df[train_cols][:training_index], df.PRICE[:training_index]\n",
    "x_test, y_test = df[train_cols][training_index:], df.PRICE[training_index:]\n",
    "\n",
    "# Scale price\n",
    "y_train = y_train / 100000\n",
    "y_test = y_test / 100000\n",
    "\n",
    "# Standardize data\n",
    "x_train_np = StandardScaler().fit_transform(x_train)\n",
    "x_test_np = StandardScaler().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc79679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR_BUILT</th>\n",
       "      <th>SQUARE_FEET</th>\n",
       "      <th>NUM_BEDROOMS</th>\n",
       "      <th>NUM_BATHROOMS</th>\n",
       "      <th>LOT_ACRES</th>\n",
       "      <th>GARAGE_SPACES</th>\n",
       "      <th>FRONT_PORCH</th>\n",
       "      <th>DECK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>3225.427066</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>2445.241759</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>2098.802852</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3823.272147</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>2568.415603</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR_BUILT  SQUARE_FEET  NUM_BEDROOMS  NUM_BATHROOMS  LOT_ACRES  \\\n",
       "0        1987  3225.427066             5            1.5       0.71   \n",
       "1        1992  2445.241759             2            2.0       0.98   \n",
       "2        1983  2098.802852             3            1.5       1.22   \n",
       "3        1990  3823.272147             4            1.0       0.96   \n",
       "4        1987  2568.415603             5            1.5       1.10   \n",
       "\n",
       "   GARAGE_SPACES  FRONT_PORCH  DECK  \n",
       "0              2            1     1  \n",
       "1              3            0     1  \n",
       "2              2            1     1  \n",
       "3              1            1     1  \n",
       "4              2            0     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9e219",
   "metadata": {},
   "source": [
    "Rearrange dataframe for SageMaker training and scale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5899543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data=x_train_np)\n",
    "train_df.columns = x_train.columns\n",
    "train_df[\"PRICE\"] = y_train / 100000\n",
    "first_col = train_df.pop(\"PRICE\")\n",
    "train_df.insert(0, \"PRICE\", first_col)\n",
    "\n",
    "test_df = pd.DataFrame(data=x_test_np)\n",
    "test_df.columns = x_test.columns\n",
    "test_df[\"PRICE\"] = y_test.reset_index(drop=True) / 100000\n",
    "first_col = test_df.pop(\"PRICE\")\n",
    "test_df.insert(0, \"PRICE\", first_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb4ee2",
   "metadata": {},
   "source": [
    "Save as both CSV and Numpy data types to demonstrate data type flexibility in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5336a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "train_df.to_csv(f\"{train_dir}/train.csv\", header=False, index=False)\n",
    "test_df.to_csv(f\"{test_dir}/test.csv\", header=False, index=False)\n",
    "\n",
    "# Save as Numpy\n",
    "np.save(os.path.join(train_dir, \"x_train.npy\"), x_train_np)\n",
    "np.save(os.path.join(test_dir, \"x_test.npy\"), x_test_np)\n",
    "np.save(os.path.join(train_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(test_dir, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93a638",
   "metadata": {},
   "source": [
    "Upload the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88ce14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket(name='sagemaker-ap-northeast-2-806174985048')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_resource_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6cb93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource_bucket = boto3.Session().resource(\"s3\").Bucket(bucket)\n",
    "s3_resource_bucket.Object(os.path.join(csv_s3_prefix, \"train.csv\")).upload_file(\n",
    "    \"data/train/train.csv\"\n",
    ")\n",
    "s3_resource_bucket.Object(os.path.join(csv_s3_prefix, \"test.csv\")).upload_file(\"data/test/test.csv\")\n",
    "s3_resource_bucket.Object(os.path.join(numpy_train_s3_prefix, \"x_train.npy\")).upload_file(\n",
    "    \"data/train/x_train.npy\"\n",
    ")\n",
    "s3_resource_bucket.Object(os.path.join(numpy_train_s3_prefix, \"y_train.npy\")).upload_file(\n",
    "    \"data/train/y_train.npy\"\n",
    ")\n",
    "s3_resource_bucket.Object(os.path.join(numpy_test_s3_prefix, \"x_test.npy\")).upload_file(\n",
    "    \"data/test/x_test.npy\"\n",
    ")\n",
    "s3_resource_bucket.Object(os.path.join(numpy_test_s3_prefix, \"y_test.npy\")).upload_file(\n",
    "    \"data/test/y_test.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89778c31",
   "metadata": {},
   "source": [
    "### Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10d271",
   "metadata": {},
   "source": [
    "스크립트 모드의 첫 번째 “level”은 종속성 없이 자신의 교육 작업, 모델 및 추론 프로세스를 정의하는 기능입니다.이것은 사용자 정의 된 파이썬 스크립트를 사용하고 SageMaker training Estimator 를 정의 할 때 해당 스크립트를 “entry point”으로 가리 킵니다. SageMaker에는 “out-of-the-box”임의 forest algorithm이 없지만 regressors 및 classifier 를 포함하여 Random Forest 구현이있는 scikit-learn 컨테이너에 대한 지원이 있습니다.여기서는 합성 주택 데이터 집합을 사용하여 주택 가격을 예측하기 위해 사용자 지정 Random Forest regressor 변수를 구현하는 방법을 보여 줍니다.\n",
    "\n",
    "SageMaker의 스크립트 모드를 사용하면 자체 도커 컨테이너를 만들고 유지하는 데 어려움을 겪지 않고도 학습 및 추론 프로세스를 제어할 수 있습니다. 예를 들어 scikit-learn 알고리즘을 사용하려는 경우 AWS에서 제공하는 scikit-learn 컨테이너를 사용하여 자신의 교육 및 추론 코드를 전달하면 됩니다. 사용자를 대신하여 SageMaker Python SDK는 이 entry point 스크립트 (학습 및/또는 추론 코드가 될 수 있음) 를 패키징하고 S3에 업로드하며 런타임 시 읽혀지는 두 개의 환경 변수를 설정하고 엔트리 포인트 스크립트에서 사용자 지정 학습 및 추론 함수를 로드합니다. 이 두 환경 변수는 패키지의 S3 경로로 설정된`SAGEMAKER_SUBMIT_DIRECTORY`와 스크립트의 이름으로 설정된 `SAGEMAKER_PROGRAM`입니다 (이 경우 'train_deploy_scikitlearn_without_dependencies.py'입니다).\n",
    "\n",
    "이 과정은 XGBoost 모델 (XGBoost 컨테이너 사용) 또는 사용자 정의 PyTorch 모델 (PyTorch 컨테이너 사용) 을 사용하려는 경우에도 동일합니다. 자신의 스크립트를 전달하기 때문에 (이것이 “스크립트 모드”라고 부르는 이유입니다) 모델, training 프로세스 및 추론 프로세스도 정의 할 수 있습니다.\n",
    "\n",
    "아래에서 우리는 우리의 사용자 정의 교육 및 추론 코드를 포함`train_deploy_scikitlearn_without_dependencies.py`라는 entry point 스크립트를 포함합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f91cbf-ed66-4125-880d-5cac49d0f588",
   "metadata": {},
   "source": [
    "hyperparameters = {\"max_depth\": 20, \"n_jobs\": 4, \"n_estimators\": 120}\n",
    "\n",
    "if enable_local_mode_training:\n",
    "    train_instance_type = \"local\"\n",
    "    inputs = {\"train\": f\"file://{train_dir}\", \"test\": f\"file://{test_dir}\"}\n",
    "else:\n",
    "    train_instance_type = \"ml.c5.xlarge\"\n",
    "    inputs = {\"train\": csv_train_s3_uri, \"test\": csv_test_s3_uri}\n",
    "\n",
    "estimator_parameters = {\n",
    "    \"entry_point\": \"train_deploy_scikitlearn_without_dependencies.py\",\n",
    "    \"source_dir\": \"scikitlearn_script\",\n",
    "    \"framework_version\": \"0.23-1\",\n",
    "    \"py_version\": \"py3\",\n",
    "    \"instance_type\": train_instance_type,\n",
    "    \"instance_count\": 1,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"randomforestregressor-model\",\n",
    "}\n",
    "\n",
    "estimator = SKLearn(**estimator_parameters)\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d4867-dd87-4ff0-a39e-8b24e0e8eff2",
   "metadata": {},
   "source": [
    "existing_endpoints = sess.sagemaker_client.list_endpoints(\n",
    "    NameContains=sklearn_endpoint_name, MaxResults=30\n",
    ")[\"Endpoints\"]\n",
    "if not existing_endpoints:\n",
    "    sklearn_predictor = estimator.deploy(\n",
    "        initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=sklearn_endpoint_name\n",
    "    )\n",
    "else:\n",
    "    sklearn_predictor = Predictor(\n",
    "        endpoint_name=\"randomforestregressor-endpoint\",\n",
    "        sagemaker_session=sess,\n",
    "        serializer=NumpySerializer(),\n",
    "        deserializer=NumpyDeserializer(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b62a38-5045-41aa-84eb-154b47a1faf9",
   "metadata": {},
   "source": [
    "prediction = sklearn_predictor.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c546f-7616-435e-ab32-a0460b03fbe3",
   "metadata": {},
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b527c",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0afdeb",
   "metadata": {},
   "source": [
    "이 PyTorch 예제에서는`pytorch_script/` 폴더에 설명 된대로 자체 파일에 넣어 코드의 나머지 부분과 실제 신경망 정의를 분리하려고합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39776c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": 25, \"batch_size\": 128, \"learning_rate\": 0.01}\n",
    "\n",
    "if enable_local_mode_training:\n",
    "    train_instance_type = \"local\"\n",
    "    inputs = {\"train\": f\"file://{train_dir}\", \"test\": f\"file://{test_dir}\"}\n",
    "else:\n",
    "    train_instance_type = \"ml.c5.xlarge\"\n",
    "    inputs = {\"train\": numpy_train_s3_uri, \"test\": numpy_test_s3_uri}\n",
    "\n",
    "estimator_parameters = {\n",
    "    \"entry_point\": \"train_deploy_pytorch_without_dependencies.py\",\n",
    "    \"source_dir\": \"pytorch_script\",\n",
    "    \"instance_type\": train_instance_type,\n",
    "    \"instance_count\": 1,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"pytorch-model\",\n",
    "    \"framework_version\": \"1.5\",\n",
    "    \"py_version\": \"py3\",\n",
    "}\n",
    "\n",
    "estimator = PyTorch(**estimator_parameters)\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad93ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sess.sagemaker_client.list_endpoints(\n",
    "    NameContains=pytorch_endpoint_name, MaxResults=30\n",
    ")[\"Endpoints\"]\n",
    "if not existing_endpoints:\n",
    "    pytorch_predictor = estimator.deploy(\n",
    "        initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=pytorch_endpoint_name\n",
    "    )\n",
    "else:\n",
    "    pytorch_predictor = Predictor(\n",
    "        endpoint_name=\"pytorch-endpoint\",\n",
    "        sagemaker_session=sess,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dfdcba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.085066795349121]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predictor.serializer = JSONSerializer()\n",
    "pytorch_predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "pytorch_predictor.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bccceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.98600000e+03, 1.96085694e+03, 2.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.99700000e+03, 3.48399130e+03, 3.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.99200000e+03, 3.38808219e+03, 2.00000000e+00, ...,\n",
       "        3.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       ...,\n",
       "       [2.00200000e+03, 3.32801007e+03, 3.00000000e+00, ...,\n",
       "        2.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [2.00200000e+03, 3.77008200e+03, 4.00000000e+00, ...,\n",
       "        2.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.99000000e+03, 2.39807633e+03, 5.00000000e+00, ...,\n",
       "        3.00000000e+00, 1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d6a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
